{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10843bab",
   "metadata": {},
   "source": [
    "# Seqence models \n",
    "\n",
    "### (video 1) Sequence problems\n",
    "Examples of sequence data\n",
    "- speach recognition: x(audio = sequence) => y(transcript = sequence)\n",
    "- music generation: x(nan; single integer, referring to a style) => y(sequence)\n",
    "- sentiment classification: x(prase = sequence) => y(stars)\n",
    "- DNA sequence analysis: x(DNA code = sequence) => y (which part corresponds to a protein = sequence)\n",
    "- machine translation: x(phrase = sequence) => y(translation = sequence)\n",
    "- video activity recognition: x(videoframes = sequence) => y(activity)\n",
    "- NER: x(phrase = sequence) => y(entities)\n",
    "\n",
    "Problems can be addressed as supervised learning with labled data X, and Y as a training set\n",
    "=> but different types of sequence problems\n",
    "- X and Y are sequences\n",
    "- X and Y can have different length or same \n",
    "- only X or Y can be the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800394d",
   "metadata": {},
   "source": [
    "### (video 2) Notations to define sequence problems\n",
    "NER: identify people\n",
    "\n",
    "\n",
    "|  | word | word | word | word | word | word | word | word | word |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| input x: | Harry | Potter | and | Hermione | Granger | invented | a | new | spell |\n",
    "| input features: | x<sup><1></sup> | x<sup><2></sup>  | ... | ... | x<sup>&lt;t&gt;</sup>  | ... | ... | x<sup><8></sup>  | x<sup><9></sup>  |\n",
    "| output y1: | 1 | 1 | 0 | 1 | 1 | 0 | 0 | 0 | 0 |\n",
    "| output: | y<sup><1></sup> | y<sup><2></sup>  | ... | ... | y<sup>&lt;t&gt;</sup>  | ... | ... | y<sup><8></sup> | y<sup><9></sup>  |\n",
    "\n",
    "y1 – not the best representation, since doesn't tell you, where is the start and end of peoples' names\n",
    "\n",
    "the input is 9 words => we'll have 9 sets of features representing these\n",
    "- x<sup>&lt;t&gt;</sup> – feature in the middle of the sequence\n",
    "- *t* implies that these are temporal sequences (but it will be used regardless the type of sequence)\n",
    "- T<sub>x</sub> – length of the input sequence = 9\n",
    "- T<sub>y</sub> – length of the output sequence = 9\n",
    "- T<sub>x</sub> and T<sub>y</sub> can be different\n",
    "        \n",
    "- X<sup>(i)</sup> – i-th training example, in this case, this particular phrase\n",
    "- x<sup>(i)&lt;t&gt; </sup> – t-th element of an input sequence of i-th training example   \n",
    "- T<sub>x</sub><sup>(i)</sup> – the length of an input sequence of i-th training example  \n",
    "- y<sup>(i)&lt;t&gt; </sup> – t-th element of an output sequence of i-th training example \n",
    "- T<sub>y</sub><sup>(i)</sup> – the length of an output sequence of i-th training example\n",
    "    \n",
    "**Representation of individual words of the sentence**\n",
    "- You come up with a vocabulary = dictionary\n",
    "- Usually 30-50k words, around 100k – not uncommon as well\n",
    "    \n",
    "    | words | number |\n",
    "    | --- | --- |\n",
    "    |[a]| 1 |\n",
    "    |[aaron]| 2 |\n",
    "    |[...]| ... |\n",
    "    |[and]| 367 |\n",
    "    |[...]| ... |\n",
    "    |[harry]| 4075 |\n",
    "    |[...]| ... |\n",
    "    |[potter]| 6830 |\n",
    "    |[...]| ... |\n",
    "    |[zulu]| 10000 |\n",
    "\n",
    "- to build this dictionaly: one of ways: find top 10k occuring words\n",
    "- then use one hot representations to encode each of this words:\n",
    "    - x<sup><1></sup> = vetor [0, ... , 1, ...., 0] with unique 1 in 4075-th position\n",
    "\n",
    "And the *goal* is given this representation for X to learn a mapping using a sequence model to then target output y, I will do this as a supervised learning problem, I'm sure given the table data with both x and y.\n",
    "    \n",
    "If you encounter a word that is not in your vocabulary, you create a new token or a new fake word called *Unknown* = UNK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf24fc0",
   "metadata": {},
   "source": [
    "### (video 3) Recurrent Neural Network (RNN) model\n",
    "\n",
    "**Why not standard network?**\n",
    "\n",
    "9 input words = [x<sup><1></sup>, ..., x<sup>&lt;t&gt;</sup>, ..., x<sup>&lt;T<sub>x</sub>&gt;</sup>]\n",
    "\n",
    "feed them into standard NN of a few layers => \n",
    "output of 9 values 0 or 1 = [y<sup><1></sup>, ..., y<sup>&lt;t&gt;</sup>, ..., y<sup>&lt;T<sub>y</sub>&gt;</sup>] \n",
    "    \n",
    "which gonna tell you whether each of those words are part of persons name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
